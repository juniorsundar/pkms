@document.meta
title: Safety of Linear Systems under Severe Sensor Attacks
description: #control-barrier-theory #journal-article
authors: juniorsundar
categories: [
    research
] 
created: 2024-04-05T12:01:05+0400
updated: 2024-05-16T13:27:40+0400
version: 1.1.1
@end

| Access {/ assets/docs/tan2024.pdf}[reference]

* Summary

  Attacked is omniscient and can spoof several system sensors at will.

  Existing results have derived necessary and sufficient conditions under which
  the state estimation problem has a unique solution.

  This paper considers severe attacking scenario when such conditions do not
  hold.

  Derive exact characterisation of set of all possible state estimates.

  Use framework of {:$/research/control-barrier-functions:}[Control Barrier Functions] to propose design principles
  for system safety in offline and online phases.
  - *Offline phase* derive conditions on safe sets for all possible sensor
    attacks encounterable during system deployments.
  - *Online phase* quadratic program-based safety filter is proposed to
    enforce system safety.

  Illustrated with 2D-vehicle example.

  Only theoretical results.

* Introduction

  In this paper:
  - certain measurements of CPS are compromised by attacker.
  - general attack model in setting of linear systems, imposes no limitations
    on the magnitude, statistical properties, or temporal evolution
    requirements on the attack signal.
  - only assuming upper bound on the number of attacked sensors.

  Existing results focus on recovering system state from compromised
  measurement data (AKA secure state reconstruction problem).

  To derive necessary and sufficient conditions to find unique solutions to
  this problem:
  - In discrete time linear system a condition is posed as a sparse
    observability property of CPS.
  - Equivalent condition for continuous time LS shows that finding unique
    solution is NP-hard in general.

  > "can we ensure safety of the system, and thereby avoid catastrophic results
  > through active control, even when certain sensors are compromised?"  

  Here, safety refers to the property to limit control system trajectories to
  remain with in a safe set via feedback

  Compromised sensor measures negatively effect or mislead state estimates.

  {:$/research/control-barrier-functions:}[Control Barrier Functions] have been applied to use cases of privacy
  preservation and safety in presence of faulty sensors. But in case of
  adversarial omniscient attacker, state estimation error does not satisfy
  assumptions of CBFs.

  This work tries to patch this shortcoming.

  Safety guarantee for CPS subject to general sensor attacks described above.
  We consider scenarios where the solution to the secure state reconstruction
  problem may not be unique.

  Contributions:
  - Provide exact characterisation of set of possible solutions to the secure
    state reconstruction problem in linear DT systems.
  - Outline design principles for safe sets in offline phase. For worst-case
    attacking scenario under mild sparse observability assumption.
  - Propose only safe control scheme that provides safety guarantees in
    presence of possibly unbounded state estimation error.

** Notation

*** Set Notation

    $[w]$ := ${1,2,...,w}$ : Denotes the set containing all natural numbers
    from 1 to $w$ .

    $∣I∣$ : Denotes the cardinality (number of elements) of the set.

*** Combinations

    $\mathbb{C}_k^w$ : Represents the set of all $k$ -combinations from the set
    [ $w$ ], where a $k$ -combination is a subset of [ $w$ ] with cardinality
    $k$ .

*** Matrix Operations

    For a matrix $C$ of size $w \times n$ and an index set $\Gamma$ that is a
    subset of [ $w$ ], $C_\Gamma$ represents a matrix obtained from $C$ by
    removing all the rows with indices not in $\Gamma$ .

*** Norm and Set Notation

    Given a point $x$ in $\mathbb{R}^n$ , a set $X$ that is a subset of
    $\mathbb{R}^n$ , and a matrix $A$ in $\mathbb{R}^{n\times n}$ , the
    notation $||x||_X$ represents the minimum distance of $x$ to any point $v$
    in $X$ . $A(X)$ represents the set of all points in $\mathbb{R}^n$ that can
    be obtained by multiplying any point $x$ in $X$ by the matrix $A$ .

*** Minkowski Summation

    $X_1 + X_2$: Represents the Minkowski sum of two sets $X_1$ and $X_2$,
    defined as the set containing all possible sums of elements where one
    element is chosen from $X_1$ and another from $X_2$ .

*** Vector and Singleton Set

    $x \in \mathbb{R}^n$ : Denotes a vector in $n$ -dimensional real space.

* Problem Formulation

  Applied to a discrete-time linear system under sensor attacks:

  Dynamics: $x(\tau + 1) = Ax(\tau) + Bu(\tau)$

  Measurement: $y(\tau)=Cx(\tau) + e(\tau)$

  Here $e(\tau)$ refers to the attacking signal.

  It is non-zero whenever a sensor $i\in[p]$ is under attack at that particular
  $\tau$ .

  Safe set: $\mathscr{C} = \{x\in\mathbb{R}^n:h(x):=Hx+q\geq 0 \}$

** Assumption

   Attacker has full knowledge of system including state, dynamics, and defense
   strategy.

   Attacker may choose $s$ out of $p$ sensors to attack. And this choice
   remains unchanged for duration considered.

   Attacker can set $e_i(\tau)$ to any value for any of these sensors.

** Problem

   *Worst-case sensor attack* - Derive condition on $H$ and $q$ s.t. system can
   be rendered safe under all possible sensor attacks.

   *Fixed yet unknown sensor attack* - Derive conditions on $H$ , $q$ and input
   sequence $\{ u(\tau) \}_{\tau \geq t}$ s.t. the system is safe.

* 2-D Example Use Case

** System Dynamics and Control

   The vehicle is modeled with position and velocity components in both $x$ and
   $y$ directions ( $x_1, x_2, x_3, x_4$ ), controlled by acceleration inputs (
   $u_1, u_2$ ).

   The system's dynamics are expressed in continuous-time, which are then
   discretized using a {:$/vault/zoh:}[Zero-Order Hold Method] with a 0.01s sampling time
   for digital control implementation.

   The output of the system includes a component representing an attacking
   signal ( $e$ ), indicating potential tampering with sensor data.

** Safety Guarantees and Sensor Attacks

   The system's safety verification involves checking for {:$/vault/sparse-observability:}[Sparse Observability],
   ensuring that even with a single sensor attack, the system's state can be
   inferred from the remaining sensors.

   A safe region ( $\mathscr{C}$ ) is defined using constraints on the position
   and velocity states of the vehicle. The system maintains safety by ensuring
   the state stays within this region even under sensor attacks.

** Online Safety and Control

   An online control strategy is outlined where the controller dynamically
   adjusts based on sensor data to mitigate any effects from tampered sensors.
   The control is designed to maintain the vehicle's state within the
   predefined safe bounds.

   During attacks, the /system assesses sensor integrity by comparing sensor
   outputs against expected values from a set of plausible vehicle states/,
   adjusted for potential tampering.

*** Key Features

**** Dynamic Safety Set ($\mathscr{C}$)

     The system uses a dynamic definition of a safe set, denoted as
     $\mathscr{C}$ , where the boundaries are defined such that all components
     of the vehicle's state (position and velocity in both $x$ and $y$
     directions) must remain within specified limits (e.g., $-4 \leq x_i \leq
     4$ for each state variable).

     This set ensures that even under the influence of malicious inputs or
     sensor errors, the control strategy can realign the vehicle back to a safe
     trajectory.

**** Sensor Attack Handling

     Sensors are susceptible to attacks where their outputs are altered to
     mislead the control system. In response, the /system evaluates the
     integrity of sensor data by comparing against a model of expected outputs
     derived from known vehicle dynamics and previously verified states/.

     By considering multiple combinations of sensor outputs and comparing them
     against theoretical trajectories, the system identifies which sensors are
     likely compromised.

**** State Estimation Under Uncertainty

     Using a brute-force approach, the system examines all possible
     combinations of sensor data to estimate the vehicle's state. This involves
     calculating the least squares solution to the equations representing
     sensor outputs and checking if the solutions meet predefined error
     thresholds.

     These plausible states are then projected forward using the vehicle
     dynamics model to predict future states, which helps in planning safe
     control actions.

**** Adaptive Control Strategy

     The control inputs ( $u(t)$ ) are adjusted based on the estimated states
     and the requirement to keep the vehicle within the safe set. This involves
     solving a quadratic programming (QP) problem where the objective is to
     minimize the deviation from nominal control inputs (based on simple
     functions like sine and cosine) while ensuring that all calculated future
     states fall within the safety constraints.

     The system employs a parameter ( $\gamma$ ), possibly representing a
     safety margin or confidence level, which adjusts the strictness of the
     safety constraint adherence.

**** Real-time Validation

     As part of its ongoing operation, the system continually checks whether
     the initially estimated plausible states (from when the system was first
     compromised) remain within the safe bounds over time.

     This involves recalculating and projecting the states every few time steps
     (e.g., $t-3$ , $t-2$ , $t-1$ , $t$ ) to ensure ongoing compliance with the
     safety requirements.

** Simulation and Results

   Simulations show the system maintaining safety constraints despite different
   attack scenarios, though some attacks lead to safety breaches when they
   cause confusion about certain state variables (e.g., $y$ -axis velocity).

   The control adjustments closely mirror nominal (intended) controls unless
   adjustments are necessary to maintain safety.

** Overall System Performance

   The system effectively handles sensor attacks by adjusting control inputs to
   ensure that both real and potential (fake) states of the vehicle remain
   within safety limits.

   The approach includes robust measures to verify sensor integrity and
   dynamically adapt to ensure continuous safe operation under potential
   cyber-attacks.


   ===
___

{:$/research/literature-review/index:}[< return] -  {:$/index:}[index]

