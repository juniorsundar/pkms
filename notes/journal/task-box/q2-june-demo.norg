@document.meta
title: Q2 June Demo
description: Task pipeline for the June 2024 Q2 Demo
authors: juniorsundar
categories: [
    task
]
created: 2024-04-04T23:08:32+0400
updated: 2024-05-14T21:21:17+0400
version: 1.1.1
@end

* Tasks

** (x) Which camera is being used for this
  - Forward: {https://shop.luxonis.com/products/oak-d-s2?variant=42455432233183}[Luxonis OAK-D S2]
    This has been tested with Release12
  - Downward: {https://shop.siyi.biz/products/siyi-a8-mini}[SIYI A8 Mini]
    This is the model being used in Masdar and in F4F Prague

*** (x) How is the data being recorded?
*** (x) It is known that the data is being dumped in ROSbags somewhere, how to extract this?
   It can be recorded using {https://github.com/tiiuae/nats-bag}[`nats-bag`]

   A laptop or GCS that is in the same NATS network can record the data
   streamed through NATS.

   @code bash
   nats-bag [-s nats://localhost:4222] record [filename]
   @end

*** (x) Is recording happening continuously or is it to be triggered?
   The gimbal stream needs to be activated by opening the stream through
   `dronsole` UI or running:

   @code bash
   nats pub video.cmd.<device-id> '{"subscriber": "id1", "subscribe":true}'
   @end

** (x) Confirm if Siyi A8 is supported for Release12
  It is supported as as confirmed by the people at F4F

** (x) Create Slack channel with all concerned parties

** (x) Fill up the hardware requirements spreadsheet

** (x) Verify the need for grass patches for the image segmentation demonstration

** (x) Data collection from testing team follow-up --> Awaiting Tintu's go-ahead 
  They don't have enough Saluki V3 to go around, so we will have to affix ours
  on a drone. Furthermore, we will have to use the x500 Holybro.

  There isn't a set method to attach the Siyi A8 camera to the drone, so we
  will have to think up some strategy, maybe by trying double tape or
  something.

** (x) Get on Solita about getting camera segmentation demo ready
*** (x) How is the video to be retrieved? Is there some code in place for this?
   Video is going to be retrieved from the NATS channel subscriber.

   There will be implementation in place to do this.

*** (x) Determine how the plugin for camera segmentation is to be implemented
   This will not be implemented as a plugin, since the image-segmentation does
   not change the state of SRTA based on outputs.

   The safe-landing container is providing coordinates to the SRTA in order to
   perform the action if the SRTA plugins so decide or its ordered from the
   FMO.

** (x) Triggering the RTA modules
*** (x) Check first what kind of triggers can be implemented with Solita
   There is a placeholder in place inside SRTA and it is awaiting the UI
   implementation on the UI/FMO side of the things.

*** (_) Check with Mehmet
    If something like this needs to be implemented in the software and control
    scheme for the drone

** (x) Printing the mounts and attach it to the drone
*** (x) Saluki V3 to Drone Mount
*** (x) Siyi A8 and Battery Mount
   .image assets/mounting_siyia8.JPG

** (_) Check if video encoding/decoding is happening on the hardware (Siyi A8)

** (_) Verify if this method can be used to record data
   For the outdoor arena demo -- talk to Jose Segovia

** (-) Mount Saluki V3 to the -Holybro-X500- T-Motor M690b Drone and get it airborne
*** (x) Obtain Saluki V3
*** (x) Set up Saluki V3 for flight mission
*** (-) Mount Saluki V3 to -Holybro- T-Motor M690b Drone

   ===
___

* Notes

  Task changes because it was possible to receive a T-Motor M690b assigned for
  SRTA Team
  - Cancelled: [Task]{**  Verify if this method can be used to record data}
  - Updated: [Task]{**  Mount Saluki V3 to the -Holybro-X500- T-Motor M690b Drone and get it airborne}

  Why go for the T-Motor drone over the Holybro?
  - Final deployment is with T-Motor drone swarms.
  - If it is possible for F4F to repeat and replicate non-normal flight test
    cases, then it can be replicated in Masdar for testing. This will save
    chances of drone being wrecked here.
  - If F4F does not have Holybro procured, then lead time to data collection is
    uncertain.



