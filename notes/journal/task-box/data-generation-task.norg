@document.meta
title: Data Generation Task
description: Data generation for faulty flights in SITL with intention to publish
authors: juniorsundar
categories: [
    task
]
created: 2024-04-04T23:00:57+0400
updated: 2024-04-09T11:24:46+0400
version: 1.1.1
@end

* (x) {:$/journal/2024/03/20:****  Literature review}[Literature review]

* (x) Generate plan of action

** (x) Figure out how to make a {:$/technical/px4/simulation:** Containerised Deployment}[Containerised Deployment]

** (x) Figure out how to set up ROS in a containerised environment

*** (x) Launch ROS in containerised environment

*** (x) Clone and build ROS 2 workspace into containerised environment

*** (x) Be able to run {:$/technical/px4/px4:* Dockerised ROS 2 CLI}[Dockerised ROS 2 CLI] as well as launch all the built nodes

*** (x) The `.bag` files need to be obtainable as well

    We may need to be able to dump the bags `.mcap` format. So this means
    that a drive needs to be mounted and exposed when launching the
    container.

** (x) Install and set up mechanism to convert log files.

   *NOTE* that the rate at which data is being recorded is throttled

** (x) Formalise a PoA

   The goal is to generate data sets that are diverse, and sufficiently large
   to be able to train and test models.

   In deployment, the experiment environment must be able to run simulations
   and record data /ad inifinitum/ given a preset list of parameters.

   The simulation may cycle through a preset list of movement tasks, or it
   may generate a randomised movement task.

   The simulation will start and end with each iteration for thorough safety
   during deployment.
   - Parameters will be cleansed to remove all faults before the simulation
     is killed.
   - Data will be recorded in bags, and all pertinent topics will be dumped.
   - ULOG file must also be copied over.
   - Fault data must also be copied over (time of injection, type, etc.).

   To that end, the following prerequisites are important to get fully set up:
   ~ ROS bags being recorded as `.mcap` files and being dumped somewhere safe.
   ~ ROS nodes to initiate rosbag records when trigger is received.
   ~ Mission controller node to handle generating executing missions.
   ~ Fault handler to trigger and record faults.
   ~ Drone state monitor that checks if the drone is functioning. If crash,
     then crash time needs to be recorded.

   *How to handle when the mission starts and finishes?*

   This is necessary for segregating the bag files, and also to manage the
   sequencing for continuous mission records.

   ? We could use the termination of the mission thread to signify a end of
   mission.
   ? Should we resort to end of mission in all chases? Even if there is a
   crash?

   Mission finishes normally -->
   - run through normal cleanup sequence
   - restart simulation.

   Drone crashes -->
   - trigger a preempt on the requesting thread
   - run cleanup sequence
   - restart simulation

* (x) Setup simulation and data collection system in local machine

** (x) Complete the data recording node with automatic folder dumping

** (x) Add auto dumping of whether the mission was completed successfully or failed

** (x) Create a HTTP server to manage the auto-launch and killing of simulation

   Since the simulation runs on a separate container this needs to be
   achieved through a server call

** (x) Expose the records/bag folder for autodump of rosbags

   @code bash
   docker run -it --rm \
       --network=host -p 14540:14540/udp \
       --ipc=host --pid=host \
       --env UID=$(id -u) \
       --env GID=$(id -g) \
       -v $(pwd)/records:/ros_workspace/records \
       px4-ros ros2
   @end

** (x) Test full pipeline for robustness for a simple deployment

* (-) Deploy to container registry

** (x) Test once and observe if it is allowed

** (-) Set up GitHub Actions to do this automatically

* (-) Run test batch

** (-) Obtain a few data sets

** (-) Create a convenient `.mcap` converter script

** (-) Actively maintain and improve the rosnodes
