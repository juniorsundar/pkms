@document.meta
title: 2 April 2024
description: 
authors: juniorsundar
categories: 
created: 2024-01-29T11:08:22+0400
updated: 2024-04-02T16:32:25+0400
version: 1.1.1
@end

* To-Do

** (-) #RESEARCH Tasks
*** (-) Is it possible to automate ROS node generation
*** ( ) What is a Hypervisor?

** (-) Update Jira
*** (-) RTA-22: Reorient for swarm
**** (-) Adjust Story title accordingly

** (x) Fly-4-Future data collection logistics
*** (x) Confirm who is being sent from Solita side for the data collection event

    Lassi Laiho is being sent from Solita side.

    "Hi @Lassi Laiho, I was made to understand that the following sets of data
    will be collected through each of the flight missions. Could you please
    confirm if this is correct?"

*** (x) Generate list of pertinent data that should be recorded

    - *Drone side*: flight records (topics and logs), drone type and parameters
      (frame type, mass, sensor+actuator parameters)
    - *Environment side*: atmospheric conditions (wind speed, temperature,
      etc.)
    - *Mission side*: mission success/failure (crashes/failures and type of
      failure), mission parameters (task coordinates/objectives)

*** (x) Confirm if this data is being recorded within DataHub
*** (x) Update 'DataHub F4F Visit Plan' on Confluence with the required topics
*** (x) Talk to Yapa about additional data collection

    Currently, the UTM team obtains weather forecast data from open-meteo.org,
    which as open-source API to obtain weather info provided the coordinates of
    the location.

    There are limitations to this as it is not on board the drone, furthermore
    there is a limit to the number of API calls you can make before incurring
    costs.

    On top of that, Lassi said that it won't be possible to record this with
    the `mission-data-recorder`

*** (x) Sync up with Martin to establish what can be gained from the event

    Go ahead with what we have. Confirm if it is possible to mark if a mission
    is failed or passed, if not then leave it.

** (-) Data Generation Task
*** (x) {:$/journal/2024/03/20:****  Literature review}[Literature review]
*** (x) Generate plan of action
**** (x) Figure out how to make a {:$/technical/px4/simulation:** Containerised Deployment}[Containerised Deployment]
**** (x) Figure out how to set up ROS in a containerised environment
***** (x) Launch ROS in containerised environment
***** (x) Clone and build ROS 2 workspace into containerised environment
***** (x) Be able to run {:$/technical/px4/px4:* Dockerised ROS 2 CLI}[Dockerised ROS 2 CLI] as well as launch all the built nodes
***** (x) The `.bag` files need to be obtainable as well

      We may need to be able to dump the bags `.mcap` format. So this means
      that a drive needs to be mounted and exposed when launching the
      container.

**** (x) Install and set up mechanism to convert log files.

     *NOTE* that the rate at which data is being recorded is throttled

**** (x) Formalise a PoA

     The goal is to generate data sets that are diverse, and sufficiently large
     to be able to train and test models.

     In deployment, the experiment environment must be able to run simulations
     and record data /ad inifinitum/ given a preset list of parameters.

     The simulation may cycle through a preset list of movement tasks, or it
     may generate a randomised movement task.

     The simulation will start and end with each iteration for thorough safety
     during deployment.
     - Parameters will be cleansed to remove all faults before the simulation
       is killed.
     - Data will be recorded in bags, and all pertinent topics will be dumped.
     - ULOG file must also be copied over.
     - Fault data must also be copied over (time of injection, type, etc.).

     To that end, the following prerequisites are important to get fully set up:
     ~ ROS bags being recorded as `.mcap` files and being dumped somewhere safe.
     ~ ROS nodes to initiate rosbag records when trigger is received.
     ~ Mission controller node to handle generating executing missions.
     ~ Fault handler to trigger and record faults.
     ~ Drone state monitor that checks if the drone is functioning. If crash,
       then crash time needs to be recorded.

     *How to handle when the mission starts and finishes?*

     This is necessary for segregating the bag files, and also to manage the
     sequencing for continuous mission records.

     ? We could use the termination of the mission thread to signify a end of
     mission.
     ? Should we resort to end of mission in all chases? Even if there is a
     crash?

     Mission finishes normally -->
     - run through normal cleanup sequence
     - restart simulation.

     Drone crashes -->
     - trigger a preempt on the requesting thread
     - run cleanup sequence
     - restart simulation

*** (-) Setup simulation and data collection system in local machine
**** (x) Complete the data recording node with automatic folder dumping
**** (x) Add auto dumping of whether the mission was completed successfully or failed
**** (x) Create a HTTP server to manage the auto-launch and killing of simulation

     Since the simulation runs on a separate container this needs to be
     achieved through a server call

**** (x) Expose the records/bag folder for autodump of rosbags

     @code bash
     docker run -it --rm \
         --network=host -p 14540:14540/udp \
         --ipc=host --pid=host \
         --env UID=$(id -u) \
         --env GID=$(id -g) \
         -v $(pwd)/records:/ros_workspace/records \
         px4-ros ros2
     @end

**** (-) Test full pipeline for robustness for a simple deployment
*** ( ) Run test batch
**** ( ) Obtain a few data sets
**** ( ) Actively maintain and improve the rosnodes

** (-) Empty data headers for Willian
*** (x) Send the data headers to Willian
*** (-) Adjust data headers with more description

    Provide header metadata in spreadsheet formats

*** ( ) Set up a meeting to determine which all data is necessary and which isn't

    ===
___

* Journal

  Its hard to have opinions because you fear that your opinions are wrong. I
  think apart from just having opinions you also need the backbone to stand up
  and say that you stand behind those opinions.

* `xz` Utils backdoor

  /{https://arstechnica.com/security/2024/04/what-we-know-about-the-xz-utils-backdoor-that-almost-infected-the-world/}[source]/

  Microsoft developer found the backdoor in the open source data compression
  utility.

  > "This might be the best executed supply chain attack we've seen described
  > in the open, and it's a nightmare scenario: malicious, competent,
  > authorized upstream in a widely used library,"
  > - Filippo Valsorda

  Andres Freund was troubleshooting performance problems in Debian was
  experiencing with SSH. SSH logins were consuming too many CPU cycles and were
  generating errors with valgrind.

  This helped him find out that the problem was a result of updates made to the
  `xz` Utils library.

  {https://cdn.arstechnica.net/wp-content/uploads/2024/04/xz-backdoor-graphic-thomas-roccia-scaled.jpg}[`xz` Backdoor Graphic -- Thomas Roccia]

** What does the backdoor do?

   Added to versions 5.6.0 and 5.6.1.

   Manipulated `sshd`, the executable file used to make SSH connections.

   Anyone in possession of a predetermined encryption key could stash any code
   of their choice in an SSH login certificate, upload it, and execute it on
   the backdoored device.

   In theory, the code could allow for just about anything, including stealing
   encryption keys or installing malware.

** How is this possible?

   Any library can tamper with inner workings of any executable it is linked
   against.

   OpenSSH doesn't link the `liblzma` library. But Debian and many other Linux
   distributions add patch to link `sshd` to `systemd`, which in turn links to
   `liblzma` which allows `xz` Utils to exert control over `sshd`.

    ===
___

{:$/journal/2024/04/01:}[< previous] - {:$/journal/index:}[index] - {:$/journal/2024/04/03:}[next >]
